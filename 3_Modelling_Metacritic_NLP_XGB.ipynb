{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Userscore</th>\n",
       "      <th>Comment</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Star Wars: Battlefront II</td>\n",
       "      <td>2.0</td>\n",
       "      <td>there nothing quite gun entire platoon clone d...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Witcher 3: Wild Hunt</td>\n",
       "      <td>10.0</td>\n",
       "      <td>game absolutely gorgeous run steady gtx hairwo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This War of Mine</td>\n",
       "      <td>10.0</td>\n",
       "      <td>really good game didnt expect first survival g...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Golden Sun</td>\n",
       "      <td>10.0</td>\n",
       "      <td>people eagerly anticipate initial release game...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assassin's Creed IV: Black Flag</td>\n",
       "      <td>8.0</td>\n",
       "      <td>best assassin creed far open world fresh missi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title  Userscore  \\\n",
       "0        Star Wars: Battlefront II        2.0   \n",
       "1         The Witcher 3: Wild Hunt       10.0   \n",
       "2                 This War of Mine       10.0   \n",
       "3                       Golden Sun       10.0   \n",
       "4  Assassin's Creed IV: Black Flag        8.0   \n",
       "\n",
       "                                             Comment lang  \n",
       "0  there nothing quite gun entire platoon clone d...   en  \n",
       "1  game absolutely gorgeous run steady gtx hairwo...   en  \n",
       "2  really good game didnt expect first survival g...   en  \n",
       "3  people eagerly anticipate initial release game...   en  \n",
       "4  best assassin creed far open world fresh missi...   en  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pickle.load(open('processed_df\\preprocessed_nlp_5p.pkl','rb'))\n",
    "# df.head()\n",
    "\n",
    "df = pd.read_csv('processed_df\\preprocessed_nlp_30p.csv')\n",
    "df.head()\n",
    "\n",
    "df100 = pd.read_csv('processed_df\\preprocessed_nlp_100p.csv')\n",
    "df100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before: (74709, 4)\n",
      "shape after: (70569, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'shape before: {df.shape}')\n",
    "df_new = df[df['Comment'] != '']\n",
    "df_new.drop_duplicates(inplace=True)\n",
    "df_new.dropna(inplace=True)\n",
    "print(f'shape after: {df_new.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before: (249031, 4)\n",
      "shape after: (235301, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'shape before: {df100.shape}')\n",
    "df100_new = df100[df100['Comment'] != '']\n",
    "df100_new.drop_duplicates(inplace=True)\n",
    "df100_new.dropna(inplace=True)\n",
    "print(f'shape after: {df100_new.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before: (74709, 4)\n",
      "shape after: (70569, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'shape before: {df.shape}')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(f'shape after: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new['Comment']\n",
    "y = df_new['Userscore']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X100 = df100_new['Comment']\n",
    "y100 = df100_new['Userscore']\n",
    "\n",
    "X100_train, X100_test, y100_train, y100_test = train_test_split(X100, y100, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- baseline, 30% data, 160 vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('tfidf', TfidfVectorizer(max_df=0.95, min_df=0.05)), ('XGBoost', XGBRegressor())]\n",
    "xgb_pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(max_df=0.95, min_df=0.05)),\n",
       "                ('XGBoost', XGBRegressor())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE 4.519310029091267\n",
      "test MAE 1.5819647954861784\n",
      "test r2 0.24648527166105128\n",
      "  \n",
      "train MSE 4.367237188106699\n",
      "train MAE 1.5534261206566233\n",
      "train r2 0.265865449814367\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_pipeline.predict(X_test)\n",
    "print(f'test MSE {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'test MAE {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'test r2 {r2_score(y_test, y_pred)}')\n",
    "\n",
    "print('  ')\n",
    "\n",
    "y_pred = xgb_pipeline.predict(X_train)\n",
    "print(f'train MSE {mean_squared_error(y_train, y_pred)}')\n",
    "print(f'train MAE {mean_absolute_error(y_train, y_pred)}')\n",
    "print(f'train r2 {r2_score(y_train, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'gamma': 0,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 1,\n",
       " 'nthread': None,\n",
       " 'objective': 'reg:linear',\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': None,\n",
       " 'silent': True,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pipeline['XGBoost'].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- baseline, 30% data, 1000 vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('tfidf', TfidfVectorizer(max_features=1000)), ('XGBoost', XGBRegressor())]\n",
    "xgb_pipeline_m = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.105666399002075 secs slipped..\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgb_pipeline_m.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(f'{end-start} secs slipped..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE 3.993797768647329\n",
      "test MAE 1.4743300248575304\n",
      "test r2 0.3341051131010562\n",
      "  \n",
      "train MSE 3.824718278293081\n",
      "train MAE 1.445663888501061\n",
      "train r2 0.35706312437801613\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_pipeline_m.predict(X_test)\n",
    "print(f'test MSE {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'test MAE {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'test r2 {r2_score(y_test, y_pred)}')\n",
    "\n",
    "print('  ')\n",
    "\n",
    "y_pred = xgb_pipeline_m.predict(X_train)\n",
    "print(f'train MSE {mean_squared_error(y_train, y_pred)}')\n",
    "print(f'train MAE {mean_absolute_error(y_train, y_pred)}')\n",
    "print(f'train r2 {r2_score(y_train, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- baseline, 30% data, 5000 vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training used 31.541131258010864 secs\n",
      "  \n",
      "test MSE 3.9503174621338166\n",
      "test MAE 1.4706294199531955\n",
      "test r2 0.34135468242463096\n",
      "  \n",
      "train MSE 3.788241365533563\n",
      "train MAE 1.442666850452882\n",
      "train r2 0.36319490994116255\n"
     ]
    }
   ],
   "source": [
    "steps = [('tfidf', TfidfVectorizer(max_features=5000)), ('XGBoost', XGBRegressor())]\n",
    "xgb_pipeline_2 = Pipeline(steps)\n",
    "\n",
    "start = time.time()\n",
    "xgb_pipeline_2.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f'training used {end-start} secs')\n",
    "print('  ')\n",
    "\n",
    "y_pred = xgb_pipeline_2.predict(X_test)\n",
    "print(f'test MSE {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'test MAE {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'test r2 {r2_score(y_test, y_pred)}')\n",
    "print('  ')\n",
    "\n",
    "y_pred = xgb_pipeline_2.predict(X_train)\n",
    "print(f'train MSE {mean_squared_error(y_train, y_pred)}')\n",
    "print(f'train MAE {mean_absolute_error(y_train, y_pred)}')\n",
    "print(f'train r2 {r2_score(y_train, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- baseline, 100% data, 5000 vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training used 107.31179189682007 secs\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "steps = [('tfidf', TfidfVectorizer(max_features=5000)), ('XGBoost', XGBRegressor())]\n",
    "xgb_pipeline_3 = Pipeline(steps)\n",
    "\n",
    "start = time.time()\n",
    "xgb_pipeline_3.fit(X100_train, y100_train)\n",
    "end = time.time()\n",
    "print(f'training used {end-start} secs')\n",
    "print('  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE 3.934551791541657\n",
      "test MAE 1.4646042223258096\n",
      "test r2 0.33982759927227246\n",
      "  \n",
      "train MSE 3.8727982137592587\n",
      "train MAE 1.456405781815883\n",
      "train r2 0.3482727056047701\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = xgb_pipeline_3.predict(X100_test)\n",
    "print(f'test MSE {mean_squared_error(y100_test, y_pred)}')\n",
    "print(f'test MAE {mean_absolute_error(y100_test, y_pred)}')\n",
    "print(f'test r2 {r2_score(y100_test, y_pred)}')\n",
    "print('  ')\n",
    "\n",
    "y_pred = xgb_pipeline_3.predict(X100_train)\n",
    "print(f'train MSE {mean_squared_error(y100_train, y_pred)}')\n",
    "print(f'train MAE {mean_absolute_error(y100_train, y_pred)}')\n",
    "print(f'train r2 {r2_score(y100_train, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('py36')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41911b0107aab6d3bca4b489e912746efb16dbe82ff72d2a51a1dcaf06f22448"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
